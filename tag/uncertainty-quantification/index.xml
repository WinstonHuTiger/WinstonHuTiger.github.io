<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Uncertainty quantification | Winston Hu</title><link>https://WinstonHuTiger.github.io/tag/uncertainty-quantification/</link><atom:link href="https://WinstonHuTiger.github.io/tag/uncertainty-quantification/index.xml" rel="self" type="application/rss+xml"/><description>Uncertainty quantification</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 20 Jun 2023 17:30:32 -0700</lastBuildDate><image><url>https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_512x512_fill_lanczos_center_3.png</url><title>Uncertainty quantification</title><link>https://WinstonHuTiger.github.io/tag/uncertainty-quantification/</link></image><item><title>Bayeisan One-Encoder-Multiple-Decoder (BOEMD) Network</title><link>https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/</link><pubDate>Tue, 20 Jun 2023 17:30:32 -0700</pubDate><guid>https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/</guid><description>&lt;DIV align="justify">
&lt;p>In this project, we&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> proposed a simple yet effective Bayesian Neural Network (BNN) framework, especifically designed for inter-rater uncertainty quantification probelm in medical imaging. We call this framework, Bayesian One-Encoder-Multiple-Decoder (BOEMD) network.&lt;/p>
&lt;figure id="figure-a-qualitative-comparison-was-performed-among-the-probabilistic-u-net-phiseg-and-boemd-the-error-map-quantifies-the-difference-between-predicted-and-observed-distributions-from-the-segmentation-outputs-and-the-error-map-one-can-see-that-our-method-captures-inter-rater-uncertainty-more-accurately-compared-to-the-others">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A qualitative comparison was performed among the probabilistic U-Net, PHiSeg and BOEMD. The error map quantifies the difference between predicted and observed distributions. From the segmentation outputs and the error map, one can see that our method captures inter-rater uncertainty more accurately compared to the others." srcset="
/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_572164a6554a281c30762d33e8945419.webp 400w,
/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_53162b47f767e5dfa13bd09b8455df36.webp 760w,
/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://WinstonHuTiger.github.io/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_572164a6554a281c30762d33e8945419.webp"
width="760"
height="329"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
A qualitative comparison was performed among the probabilistic U-Net, PHiSeg and BOEMD. The error map quantifies the difference between predicted and observed distributions. From the segmentation outputs and the error map, one can see that our method captures inter-rater uncertainty more accurately compared to the others.
&lt;/figcaption>&lt;/figure>
&lt;p>Automated medical image segmentation inherently involves a certain degree of uncerainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. Such modeling of segmentation uncertainty, known as inter-rater uncertainty is explored and analyzed in this project.&lt;/p>
&lt;figure id="figure-a-schematic-view-of-our-architecture-to-estimate-inter-rater-uncertainty-with-bayesian-modeling-it-contains-one-bayesian-encoder-and-multiple-bayesian-decoders-in-the-skip-connection-red-blue-and-green-between-the-encoder-and-each-decoder-an-attention-module-denoted-by-a-is-introduced-to-capture-rater-specific-representation-for-individual-raters">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="A schematic view of our architecture to estimate inter-rater uncertainty with Bayesian modeling. It contains one Bayesian encoder and multiple Bayesian decoders. In the skip connection (red, blue, and green) between the encoder and each decoder, an attention module (denoted by A) is introduced to capture rater-specific representation for individual raters." srcset="
/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_5d4c4d1e0c9c0e04ec6d5d51b31a27bd.webp 400w,
/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_a331e41e1d17c9317d82c8243f6fb935.webp 760w,
/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://WinstonHuTiger.github.io/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_5d4c4d1e0c9c0e04ec6d5d51b31a27bd.webp"
width="760"
height="404"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
A schematic view of our architecture to estimate inter-rater uncertainty with Bayesian modeling. It contains one Bayesian encoder and multiple Bayesian decoders. In the skip connection (red, blue, and green) between the encoder and each decoder, an attention module (denoted by A) is introduced to capture rater-specific representation for individual raters.
&lt;/figcaption>&lt;/figure>
&lt;p>BOEMD has three main features:&lt;/p>
&lt;ul>
&lt;li>One-Encoder-Multiple-Decoder: the only one encoder is designed to learn the shared knowledge from segmentation while the multiple decoders that are &lt;em>aligned&lt;/em> with each rater (if the rater ids are known, attends to learn the specific features from each rater. If the rater ids are unknown, each decoder learns the shared knowledge as the encoder does.&lt;/li>
&lt;li>Rater-specific Attention: each attention unit is associated with one decoder, to further enhance the ability of decoder capturing the specific knowledge from segmentation map.&lt;/li>
&lt;li>Bayesian Modelling: usually medical imaging dataset is quite small compared to other existing vision dataset, which results in the neural network over-fitting. Adopting Bayesian Modelling in our framework helps the neural network learn the dataset distribution from a high level. Doing this also reduces over-fitting.&lt;/li>
&lt;/ul>
&lt;/DIV>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Qingqiao Hu and Hao Wang made equal contribution to this project.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>