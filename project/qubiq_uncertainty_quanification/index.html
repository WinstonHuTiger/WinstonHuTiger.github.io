<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: February 17, 2025 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.eb88373e25b310d1e867674d2a4c94a3.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"' disabled><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"'><meta name=author content="Winston Hu"><meta name=description content="In this project, we1 proposed a simple yet effective Bayesian Neural Network (BNN) framework, especifically designed for inter-rater uncertainty quantification probelm in medical imaging. We call this framework, Bayesian One-Encoder-Multiple-Decoder (BOEMD) network."><link rel=alternate hreflang=en-us href=https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/><link rel=canonical href=https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#bbdefb"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Winston Hu"><meta property="og:url" content="https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/"><meta property="og:title" content="Bayeisan One-Encoder-Multiple-Decoder (BOEMD) Network | Winston Hu"><meta property="og:description" content="In this project, we1 proposed a simple yet effective Bayesian Neural Network (BNN) framework, especifically designed for inter-rater uncertainty quantification probelm in medical imaging. We call this framework, Bayesian One-Encoder-Multiple-Decoder (BOEMD) network."><meta property="og:image" content="https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-06-20T17:30:32-07:00"><meta property="article:modified_time" content="2023-06-20T17:30:32-07:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://WinstonHuTiger.github.io/project/qubiq_uncertainty_quanification/"},"headline":"Bayeisan One-Encoder-Multiple-Decoder (BOEMD) Network","datePublished":"2023-06-20T17:30:32-07:00","dateModified":"2023-06-20T17:30:32-07:00","author":{"@type":"Person","name":"Qingqiao Hu"},"publisher":{"@type":"Organization","name":"Winston Hu","logo":{"@type":"ImageObject","url":"https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_192x192_fill_lanczos_center_3.png"}},"description":"In this project, we1 proposed a simple yet effective Bayesian Neural Network (BNN) framework, especifically designed for inter-rater uncertainty quantification probelm in medical imaging. We call this framework, Bayesian One-Encoder-Multiple-Decoder (BOEMD) network."}</script><title>Bayeisan One-Encoder-Multiple-Decoder (BOEMD) Network | Winston Hu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=54b83032c201051af91db4ec6b2d7c17><script src=/js/wowchemy-init.min.2a7b4dc7d7846171b6299e17e1f3ac71.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Winston Hu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Winston Hu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>Bayeisan One-Encoder-Multiple-Decoder (BOEMD) Network</h1><div class=article-metadata><div><span>Qingqiao Hu</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Hao Wang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Jing Luo</span>, <span>Yunhao Luo</span>, <span>Zhiheng Zhang</span>, <span>Jan S. Kirschke</span>, <span>Benedikt Wiestler</span>, <span>Bjoern Menze</span>, <span>Jianguo Zhang</span>, <span>Hongwei Bran Li</span></div><span class=article-date>Jun 20, 2023</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/pdf/2306.16556v1.pdf target=_blank rel=noopener>PDF
</a><a class="btn btn-outline-primary btn-page-header" href=https://github.com/HaoWang420/bOEMD-net target=_blank rel=noopener>Code</a></div></div><div class=article-container><div class=article-style><div align=justify><p>In this project, we<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> proposed a simple yet effective Bayesian Neural Network (BNN) framework, especifically designed for inter-rater uncertainty quantification probelm in medical imaging. We call this framework, Bayesian One-Encoder-Multiple-Decoder (BOEMD) network.</p><figure id=figure-a-qualitative-comparison-was-performed-among-the-probabilistic-u-net-phiseg-and-boemd-the-error-map-quantifies-the-difference-between-predicted-and-observed-distributions-from-the-segmentation-outputs-and-the-error-map-one-can-see-that-our-method-captures-inter-rater-uncertainty-more-accurately-compared-to-the-others><div class="d-flex justify-content-center"><div class=w-100><img alt="A qualitative comparison was performed among the probabilistic U-Net, PHiSeg and BOEMD. The error map quantifies the difference between predicted and observed distributions. From the segmentation outputs and the error map, one can see that our method captures inter-rater uncertainty more accurately compared to the others." srcset="/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_572164a6554a281c30762d33e8945419.webp 400w,
/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_53162b47f767e5dfa13bd09b8455df36.webp 760w,
/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/media/images/uncertainty_comparison_v3_hua05f57b1381b6cbf6b945b0259f29d9c_533509_572164a6554a281c30762d33e8945419.webp width=760 height=329 loading=lazy data-zoomable></div></div><figcaption data-pre=Figure&nbsp; data-post=:&nbsp; class=numbered>A qualitative comparison was performed among the probabilistic U-Net, PHiSeg and BOEMD. The error map quantifies the difference between predicted and observed distributions. From the segmentation outputs and the error map, one can see that our method captures inter-rater uncertainty more accurately compared to the others.</figcaption></figure><p>Automated medical image segmentation inherently involves a certain degree of uncerainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. Such modeling of segmentation uncertainty, known as inter-rater uncertainty is explored and analyzed in this project.</p><figure id=figure-a-schematic-view-of-our-architecture-to-estimate-inter-rater-uncertainty-with-bayesian-modeling-it-contains-one-bayesian-encoder-and-multiple-bayesian-decoders-in-the-skip-connection-red-blue-and-green-between-the-encoder-and-each-decoder-an-attention-module-denoted-by-a-is-introduced-to-capture-rater-specific-representation-for-individual-raters><div class="d-flex justify-content-center"><div class=w-100><img alt="A schematic view of our architecture to estimate inter-rater uncertainty with Bayesian modeling. It contains one Bayesian encoder and multiple Bayesian decoders. In the skip connection (red, blue, and green) between the encoder and each decoder, an attention module (denoted by A) is introduced to capture rater-specific representation for individual raters." srcset="/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_5d4c4d1e0c9c0e04ec6d5d51b31a27bd.webp 400w,
/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_a331e41e1d17c9317d82c8243f6fb935.webp 760w,
/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/media/images/main_model_v2_hu9cacbab7a997fe8a80340fdba48124ba_357025_5d4c4d1e0c9c0e04ec6d5d51b31a27bd.webp width=760 height=404 loading=lazy data-zoomable></div></div><figcaption data-pre=Figure&nbsp; data-post=:&nbsp; class=numbered>A schematic view of our architecture to estimate inter-rater uncertainty with Bayesian modeling. It contains one Bayesian encoder and multiple Bayesian decoders. In the skip connection (red, blue, and green) between the encoder and each decoder, an attention module (denoted by A) is introduced to capture rater-specific representation for individual raters.</figcaption></figure><p>BOEMD has three main features:</p><ul><li>One-Encoder-Multiple-Decoder: the only one encoder is designed to learn the shared knowledge from segmentation while the multiple decoders that are <em>aligned</em> with each rater (if the rater ids are known, the encoder tends to learn the specific features from each rater; otherwise, the rater ids are unknown, each decoder learns the shared knowledge as the encoder does.)</li><li>Rater-specific Attention: each attention unit is associated with one decoder, to further enhance the ability of decoder capturing the specific knowledge from segmentation map.</li><li>Bayesian Modelling: usually medical imaging dataset is quite small compared to other existing vision dataset, which results in the neural network over-fitting. Adopting Bayesian Modelling in our framework helps the neural network learn the dataset distribution from a high level. Doing this also reduces over-fitting.</li></ul><p>We also introduced a rater-aligned liver tumor dataset in this work to further demonstrate the intention of our design.</p></div><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Qingqiao Hu and Hao Wang made equal contribution to this project.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=article-tags><a class="badge badge-light" href=/tag/uncertainty-quantification/>Uncertainty quantification</a>
<a class="badge badge-light" href=/tag/segmentation/>Segmentation</a>
<a class="badge badge-light" href=/tag/inter-rater-variability/>Inter-rater variability</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F&amp;text=Bayeisan+One-Encoder-Multiple-Decoder+%28BOEMD%29+Network" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F&amp;t=Bayeisan+One-Encoder-Multiple-Decoder+%28BOEMD%29+Network" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Bayeisan%20One-Encoder-Multiple-Decoder%20%28BOEMD%29%20Network&amp;body=https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F&amp;title=Bayeisan+One-Encoder-Multiple-Decoder+%28BOEMD%29+Network" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Bayeisan+One-Encoder-Multiple-Decoder+%28BOEMD%29+Network%20https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fproject%2Fqubiq_uncertainty_quanification%2F&amp;title=Bayeisan+One-Encoder-Multiple-Decoder+%28BOEMD%29+Network" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="project-related-pages content-widget-hr"><h2>Publications</h2><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/my_qubiq_uncertainty/>Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks</a></div><a href=/publication/my_qubiq_uncertainty/ class=summary-link><div class=article-style>Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this …</div></a><div class="stream-meta article-metadata"><div><span>Qingqiao Hu</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Hao Wang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Jing Luo</span>, <span>Yunhao Luo</span>, <span>Zhiheng Zhangg</span>, <span>Jan S. Kirschke</span>, <span>Benedikt Wiestler</span>, <span>Bjoern Menze</span>, <span>Jianguo Zhang</span>, <span>Hongwei Bran Li</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2306.16556v1.pdf target=_blank rel=noopener>PDF
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/HaoWang420/bOEMD-net target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/qubiq_uncertainty_quanification/>Project</a></div></div><div class=ml-3></div></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2025 Winston Hu. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.e250aa98ea6f87c6f943e9e06909f6ca.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>