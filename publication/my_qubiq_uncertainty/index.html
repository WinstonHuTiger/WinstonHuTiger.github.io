<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: July 25, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.eb88373e25b310d1e867674d2a4c94a3.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"' disabled><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"'><meta name=author content="Winston Hu"><meta name=description content="Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We also provide an open-source 3D multi-rater dataset with three raters annotated liver lesions in CT images as an additional contribution. This dataset serves as an independent resource for further research in the field. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available mph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Furthermore, on the mph{LIDC-IDRI} dataset, our approach demonstrates superior performance and accurately captures the inter-rater distribution of segmentations. Our codes, models, and the new dataset are available through our GitHub repository: https://github.com/HaoWang420/bOEMD-net"><link rel=alternate hreflang=en-us href=https://WinstonHuTiger.github.io/publication/my_qubiq_uncertainty/><link rel=canonical href=https://WinstonHuTiger.github.io/publication/my_qubiq_uncertainty/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#bbdefb"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Winston Hu"><meta property="og:url" content="https://WinstonHuTiger.github.io/publication/my_qubiq_uncertainty/"><meta property="og:title" content="Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks | Winston Hu"><meta property="og:description" content="Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We also provide an open-source 3D multi-rater dataset with three raters annotated liver lesions in CT images as an additional contribution. This dataset serves as an independent resource for further research in the field. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available mph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Furthermore, on the mph{LIDC-IDRI} dataset, our approach demonstrates superior performance and accurately captures the inter-rater distribution of segmentations. Our codes, models, and the new dataset are available through our GitHub repository: https://github.com/HaoWang420/bOEMD-net"><meta property="og:image" content="https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-07-01T20:46:34-07:00"><meta property="article:modified_time" content="2023-07-01T20:46:34-07:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://WinstonHuTiger.github.io/publication/my_qubiq_uncertainty/"},"headline":"Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks","datePublished":"2023-07-01T20:46:34-07:00","dateModified":"2023-07-01T20:46:34-07:00","author":{"@type":"Person","name":"Qingqiao Hu*"},"publisher":{"@type":"Organization","name":"Winston Hu","logo":{"@type":"ImageObject","url":"https://WinstonHuTiger.github.io/media/icon_hu60d8226fe61b6d7b6af2c2389494e24b_10520_192x192_fill_lanczos_center_3.png"}},"description":"Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We also provide an open-source 3D multi-rater dataset with three raters annotated liver lesions in CT images as an additional contribution. This dataset serves as an independent resource for further research in the field. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available \u001bmph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Furthermore, on the \u001bmph{LIDC-IDRI} dataset, our approach demonstrates superior performance and accurately captures the inter-rater distribution of segmentations. Our codes, models, and the new dataset are available through our GitHub repository: https://github.com/HaoWang420/bOEMD-net"}</script><title>Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks | Winston Hu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=e6c5464c6a3769223acf0f276dc18899><script src=/js/wowchemy-init.min.2a7b4dc7d7846171b6299e17e1f3ac71.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Winston Hu</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Winston Hu</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#teaching><span>Teaching</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks</h1><div class=article-metadata><div><span>Qingqiao Hu*</span>, <span>Hao Wang*</span>, <span>Jing Luo</span>, <span>Yunhao Luo</span>, <span>Zhiheng Zhangg</span>, <span>Jan S. Kirschke</span>, <span>Benedikt Wiestler</span>, <span>Bjoern Menze</span>, <span>Jianguo Zhang</span>, <span>Hongwei Bran Li</span></div><span class=article-date>July 2023</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/pdf/2306.16556v1.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/HaoWang420/bOEMD-net target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header" href=/project/qubiq_uncertainty_quanification/>Project</a></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We also provide an open-source 3D multi-rater dataset with three raters annotated liver lesions in CT images as an additional contribution. This dataset serves as an independent resource for further research in the field. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available mph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Furthermore, on the mph{LIDC-IDRI} dataset, our approach demonstrates superior performance and accurately captures the inter-rater distribution of segmentations. Our codes, models, and the new dataset are available through our GitHub repository: <a href=https://github.com/HaoWang420/bOEMD-net target=_blank rel=noopener>https://github.com/HaoWang420/bOEMD-net</a></p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#2>Journal article</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">arXiv 2023</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/uncertainty-quantification/>Uncertainty quantification</a>
<a class="badge badge-light" href=/tag/segmentation/>Segmentation</a>
<a class="badge badge-light" href=/tag/inter-rater-variability/>Inter-rater variability</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F&amp;text=Inter-Rater+Uncertainty+Quantification+in+Medical+Image+Segmentation+via+Rater-Specific+Bayesian+Neural+Networks" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F&amp;t=Inter-Rater+Uncertainty+Quantification+in+Medical+Image+Segmentation+via+Rater-Specific+Bayesian+Neural+Networks" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Inter-Rater%20Uncertainty%20Quantification%20in%20Medical%20Image%20Segmentation%20via%20Rater-Specific%20Bayesian%20Neural%20Networks&amp;body=https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F&amp;title=Inter-Rater+Uncertainty+Quantification+in+Medical+Image+Segmentation+via+Rater-Specific+Bayesian+Neural+Networks" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Inter-Rater+Uncertainty+Quantification+in+Medical+Image+Segmentation+via+Rater-Specific+Bayesian+Neural+Networks%20https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2FWinstonHuTiger.github.io%2Fpublication%2Fmy_qubiq_uncertainty%2F&amp;title=Inter-Rater+Uncertainty+Quantification+in+Medical+Image+Segmentation+via+Rater-Specific+Bayesian+Neural+Networks" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 Winston Hu. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.32ee83730ed883becad04bc5170512cc.js></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.c7af8ef9d6716c221ea3eb7b0c2bf640.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>